# -*- coding: utf-8 -*-
"""ImageClassifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14PDrCi2G1X1N4hCqp6QzHaEKdz5dIg-3
"""

from gzip import READ
import torch
from torch.utils.data import Dataset , DataLoader
import torch.nn as nn
import os
import numpy as np
import sys
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from torchvision import transforms
from torchvision.models import vgg16
from PIL import Image
from tqdm import tqdm
import random
torch.manual_seed(3)
torch.cuda.manual_seed_all(3)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(3)
random.seed(3)
os.environ['PYTHONHASHSEED'] = str(3)
device = "cuda"
patience = 3
num_epochs = 10

class Dataset(Dataset):
    def __init__(self, X, y):
        super(Dataset, self).__init__()
        self.X = X
        self.y = y

    def __getitem__(self, index):
        sample = {}
        sample["x"] = torch.tensor(self.X[index], dtype=torch.float32)
        sample["y"] = torch.tensor(self.y[index], dtype=torch.float32)
        return sample

    def __len__(self):
        return len(self.X)

def load_dataset():
    path = './datasets/resized_animal_10/content/processed_data'
    classes = ['ragno', 'scoiattolo', 'cane', 'gatto', 'farfalla']
    ds = []
    y = []
    for i, name in enumerate(classes):
        class_path = os.path.join(path, name)
        imgs = os.listdir(class_path)
        img_paths = [os.path.join(class_path, img_path) for img_path in imgs]
        ds.extend(img_paths)
        y.extend(len(imgs) * [i])
    X = ds
    y = np.array(y)
    return X, y.astype(np.float64)

def make_dataloaders(X, y, batch_size=8, test_split=0.1):
    X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=test_split)
    train_ds = Dataset(X_train, Y_train)
    val_ds = Dataset(X_val, Y_val)
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True, pin_memory=True)
    return train_loader, val_loader

class Dataset(Dataset):
    def __init__(self, X, y):
        super(Dataset, self).__init__()
        self.X = X
        self.y = y
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        img_size = 224
        # make some augmentations on training data
        self.train_transform = transforms.Compose([
            transforms.RandomResizedCrop((img_size, img_size)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean, std)
        ])

    def __getitem__(self, index):
        sample = {}
        img = Image.open(self.X[index])
        img = self.train_transform(img)
        sample['x'] = img
        sample["y"] = torch.tensor(self.y[index], dtype=torch.float32)
        return sample

    def __len__(self):
        return len(self.X)

def train_classifier(model) :
  X,y = load_dataset()
  train_loader , val_loader = make_dataloaders(X = X, y = y , batch_size= 4)
  # for sample in
  # model = get_classifier_model(num_feat)
  criterion = nn.CrossEntropyLoss(reduction = 'mean')
  optimizer = torch.optim.Adam(model.parameters() , lr = float(1e-3))
  epoch_start= 0
  avg_losses = []
  avg_losses_val = []
  avg_acc = []
  last_loss = np.Inf
  for epoch in range(epoch_start, num_epochs):
    total_step = len(train_loader)
    print(total_step)
    model.train()
    sum_loss = 0
    for i, sample in tqdm(enumerate(train_loader)):
      # Move tensors to the configured device
      x = sample['x'].to(device)
      y = sample['y'].to(device).long()
      pred_x = model(x)
      loss = criterion(pred_x , y)
      # Backward and optimize
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
      sum_loss += loss.item()
    avg_loss = sum_loss / total_step
    print('Loss(Train) of the network after {} epochs {}'.format(epoch
    ,avg_loss))
    avg_losses.append(avg_loss)
    with torch.no_grad() :
      model.eval()
      total_step = len(val_loader)
      sum_loss , total , correct = 0 , 0 , 0
      for i, sample in enumerate(val_loader):
        # Move tensors to the configured device
        x = sample['x'].to(device)
        y = sample['y'].to(device).long()
        # Forward pass
        x_pred = model(x)
        loss = criterion(x_pred , y)
        sum_loss += loss.item()
        _, predicted = torch.max(x_pred.data, 1)
        total += y.size(0)
        correct += (predicted == y).sum().item()
    acc = 100 * correct / total
    print('Accuracy of the network after {} epochs {} %'.format(epoch ,acc))
    avg_acc.append(acc)
    avg_loss_val = sum_loss / total_step
    print('Loss(Val) of the network after {} epochs {}'.format(epoch
    ,avg_loss_val))
    avg_losses_val.append(avg_loss_val)
    torch.save({ 'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    },
    f"./output/q1/checkpoints/ckpt_classification_{epoch}.pth")

    if avg_loss_val > last_loss:
      trigger_times += 1
      print('Trigger Times:', trigger_times)
      if trigger_times >= patience:
        print('Early stopping!')
        torch.save({
        'epoch' : epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        },
        f"./output/q1/checkpoints_classification/ckpt_{epoch}.pth")
        break
    else:
      print('trigger times: 0')
      trigger_times = 0
    last_loss = avg_loss_val
  plt.plot(avg_losses_val)
  plt.plot(avg_losses)
  plt.show()
  return model

class ConvNet(nn.Module) :
  def __init__(self , num_channels = 32) :
    super(ConvNet ,self).__init__()
    self.conv1 = nn.Conv2d(in_channels= 3 , out_channels= 4 ,
    kernel_size=(3,3) , stride = (1,1))
    self.avgpooling1 = nn.AvgPool2d(kernel_size=(2,2) , stride=(2,2))
    self.conv2 = nn.Conv2d(in_channels= 4 , out_channels= num_channels ,
    kernel_size=(3,3) , stride = (1,1))
    self.avgpooling2 = nn.AvgPool2d(kernel_size=(2,2) , stride = (2,2))
    self.flatten =nn.Flatten() #nn.AdaptiveAvgPool2d((16,16))
    self.fc1 = nn.Linear(in_features= 54 * 54 * num_channels ,out_features=
    1024)
    self.dropout = nn.Dropout(0.5)
    self.fc2 = nn.Linear(in_features= 1024 , out_features= 5)
    # # self.fc3 = nn.Linear(in_features= 1024 , out_features= 512)
    # self.fc3 = nn.Linear(in_features= 512 , out_features= 5)
    self.relu = nn.ReLU()

  def forward(self , x) :
    x = self.conv1(x)
    x = self.avgpooling1(x)
    x = self.dropout(x)
    x = self.conv2(x)
    x = self.avgpooling2(x)
    x = self.dropout(x)
    x = self.flatten(x)
    x = self.fc1(x)
    x = self.dropout(x)
    x = self.relu(x)
    x = self.fc2(x)
    return x

import torch
import torch.nn as nn
X,y = load_dataset()
train_loader , val_loader = make_dataloaders(X = X, y = y , batch_size = 2)
model = ConvNet(32)
print(model)
model = train_classifier(model.to(device))
torch.save(model.state_dict() , "output/q4model.pth")

